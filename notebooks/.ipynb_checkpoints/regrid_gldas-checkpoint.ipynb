{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect NLDAS Forcing Data\n",
    "\n",
    "This notebook demonstrates the process of collecting NLDAS forcing data, regridding these data onto an existing WRF-Hydro (domain collected in the previous notebook), and finally saving the results to HydroShare. \n",
    "\n",
    "See this [link](https://hydro1.gesdisc.eosdis.nasa.gov/data/NLDAS/README.NLDAS2.pdf) for details about primary (FORA) and secondary (FORB) NLDAS forcing datasets. The following steps are completed in the https://urs.earthdata.nasa.gov/ website:\n",
    "\n",
    "1. Create Earthdata account: [link](https://urs.earthdata.nasa.gov/users/new)\n",
    "2. Link GES DISC with your earthdata account: [link](https://disc.gsfc.nasa.gov/earthdata-login)\n",
    "3. Select NLDAS2 data via: [https://disc.gsfc.nasa.gov/datasets/NLDAS_FORA0125_H_V002/summary?keywords=NLDAS](https://disc.gsfc.nasa.gov/datasets/NLDAS_FORA0125_H_V002/summary?keywords=NLDAS) and subset the data to a reasonable size and date range using the `Simple Subset Wizard`.  \n",
    "5. Choose the following variables to extract:\n",
    "    - 10-m above ground Meridional wind speed\n",
    "    - 10-m above ground Zonal wind speed \n",
    "    - 2-m above ground Specific humidity\n",
    "    - 2-m above ground Temperature \n",
    "    - LW radiation flux downwards\n",
    "    - Precipitation hourly total\n",
    "    - Surface pressure\n",
    "    - SW radiation flux downwards\n",
    "6. Select \"Subset Selected Data Sets\" \n",
    "7. Select \"View Subset Results\"\n",
    "8. Above the list of files, select the \"list of URLs\" link and copy the contents below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use `bash` to download these data as described [here](https://disc.gsfc.nasa.gov/information/howto/5761bc6a5ad5a18811681bae/how-to-download-data-files-from-http-service-with-wget?keywords=wget). Replace the `<list of URLs>` placholder below with the URL's from Step 7 (above) to write all of the NLDAS URLs to a text file which will be used later to perform a bulk download."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "\n",
    "# make a directory for the raw forcing data\n",
    "mkdir input_files\n",
    "\n",
    "# create a file of urls to download\n",
    "cat > input_files/urls.txt\n",
    "<list of URLS>\n",
    "\n",
    "# E.G.\n",
    "# cat > input_files/urls.txt\n",
    "#http://hydro1.gesdisc.eosdis.nasa.gov/daac-bin/OTF/HTTP_services.cgi?FILENAME=%2Fdata%2FNLDAS%2FNLDAS_FORA0125_H.002%2F2018%2F213%2FNLDAS_FORA0125_H.A20180801.0000.002.grb&FORMAT=R3JpYi8&BBOX=35.42%2C-96.64%2C44.87%2C-82.49&LABEL=NLDAS_FORA0125_H.A20180801.0000.002.2019078181032.pss.grb&SHORTNAME=NLDAS_FORA0125_H&SERVICE=SUBSET_GRIB&VERSION=1.02&LAYERS=PwM&DATASET_VERSION=002\n",
    "#http://hydro1.gesdisc.eosdis.nasa.gov/daac-bin/OTF/HTTP_services.cgi?FILENAME=%2Fdata%2FNLDAS%2FNLDAS_FORA0125_H.002%2F2018%2F213%2FNLDAS_FORA0125_H.A20180801.0100.002.grb&FORMAT=R3JpYi8&BBOX=35.42%2C-96.64%2C44.87%2C-82.49&LABEL=NLDAS_FORA0125_H.A20180801.0100.002.2019078181032.pss.grb&SHORTNAME=NLDAS_FORA0125_H&SERVICE=SUBSET_GRIB&VERSION=1.02&LAYERS=PwM&DATASET_VERSION=002\n",
    "#http://hydro1.gesdisc.eosdis.nasa.gov/daac-bin/OTF/HTTP_services.cgi?FILENAME=%2Fdata%2FNLDAS%2FNLDAS_FORA0125_H.002%2F2018%2F213%2FNLDAS_FORA0125_H.A20180801.0200.002.grb&FORMAT=R3JpYi8&BBOX=35.42%2C-96.64%2C44.87%2C-82.49&LABEL=NLDAS_FORA0125_H.A20180801.0200.002.2019078181032.pss.grb&SHORTNAME=NLDAS_FORA0125_H&SERVICE=SUBSET_GRIB&VERSION=1.02&LAYERS=PwM&DATASET_VERSION=002\n",
    "#http://hydro1.gesdisc.eosdis.nasa.gov/daac-bin/OTF/HTTP_services.cgi?FILENAME=%2Fdata%2FNLDAS%2FNLDAS_FORA0125_H.002%2F2018%2F213%2FNLDAS_FORA0125_H.A20180801.0300.002.grb&FORMAT=R3JpYi8&BBOX=35.42%2C-96.64%2C44.87%2C-82.49&LABEL=NLDAS_FORA0125_H.A20180801.0300.002.2019078181032.pss.grb&SHORTNAME=NLDAS_FORA0125_H&SERVICE=SUBSET_GRIB&VERSION=1.02&LAYERS=PwM&DATASET_VERSION=002\n",
    "#http://hydro1.gesdisc.eosdis.nasa.gov/daac-bin/OTF/HTTP_services.cgi?FILENAME=%2Fdata%2FNLDAS%2FNLDAS_FORA0125_H.002%2F2018%2F213%2FNLDAS_FORA0125_H.A20180801.0400.002.grb&FORMAT=R3JpYi8&BBOX=35.42%2C-96.64%2C44.87%2C-82.49&LABEL=NLDAS_FORA0125_H.A20180801.0400.002.2019078181032.pss.grb&SHORTNAME=NLDAS_FORA0125_H&SERVICE=SUBSET_GRIB&VERSION=1.02&LAYERS=PwM&DATASET_VERSION=002\n",
    "#http://hydro1.gesdisc.eosdis.nasa.gov/daac-bin/OTF/HTTP_services.cgi?FILENAME=%2Fdata%2FNLDAS%2FNLDAS_FORA0125_H.002%2F2018%2F213%2FNLDAS_FORA0125_H.A20180801.0500.002.grb&FORMAT=R3JpYi8&BBOX=35.42%2C-96.64%2C44.87%2C-82.49&LABEL=NLDAS_FORA0125_H.A20180801.0500.002.2019078181032.pss.grb&SHORTNAME=NLDAS_FORA0125_H&SERVICE=SUBSET_GRIB&VERSION=1.02&LAYERS=PwM&DATASET_VERSION=002\n",
    "#http://hydro1.gesdisc.eosdis.nasa.gov/daac-bin/OTF/HTTP_services.cgi?FILENAME=%2Fdata%2FNLDAS%2FNLDAS_FORA0125_H.002%2F2018%2F213%2FNLDAS_FORA0125_H.A20180801.0600.002.grb&FORMAT=R3JpYi8&BBOX=35.42%2C-96.64%2C44.87%2C-82.49&LABEL=NLDAS_FORA0125_H.A20180801.0600.002.2019078181032.pss.grb&SHORTNAME=NLDAS_FORA0125_H&SERVICE=SUBSET_GRIB&VERSION=1.02&LAYERS=PwM&DATASET_VERSION=002"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follow the instructions [here](https://disc.gsfc.nasa.gov/data-access#mac_linux_wget) for setting up your EarthData account for downloading data. Replace the `<uid>` and `<password>` placeholders below with your EarthData credentials.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "if [ ! -f ~/.netrc ]; then\n",
    "    touch ~/.netrc\n",
    "    echo \"machine urs.earthdata.nasa.gov login <uid> password <password>\" >> ~/.netrc\n",
    "    chmod 0600 .netrc\n",
    "    touch ~/.urs_cookies\n",
    "fi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the files listed in `input_files/urls.txt` using `wget`. This may take several minutes depending on how many files you're downloading. This following command can be executed in a terminal window to count the files as they're downloaded:\n",
    "\n",
    "```\n",
    "$watch \"ls -l <path to data>/input_files | wc -l\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# download these data via wget\n",
    "cd input_files\n",
    "wget --load-cookies ~/.urs_cookies \\\n",
    "     --save-cookies ~/.urs_cookies \\\n",
    "     --auth-no-challenge=on \\\n",
    "     --keep-session-cookies \\\n",
    "     --content-disposition \\\n",
    "     -i urls.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preview the data that we downloaded. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "du -h input_files/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data that we've downloaded are NLDAS NetCDF files that have been subsetted through time, space, and variable. These data still need to be regridded to the WRF-Hydro domain that was collected in the previous notebook.\n",
    "\n",
    "Create regridding 'weight' files required by the ESMF regridders. The weight files are netCDF files which specify interpolation weights between the source coordinate data grids (src) and destination coordinate data (dst) grids. The weight file is generated by running the `NLDAS2WRFHydro_generate_weights.ncl` script. We'll need to provide the source and destination grid filenames as arguments to the script, for example:\n",
    "\n",
    "```\n",
    "$ ncl interp_opt=\"bilinear\"\n",
    "    srcGridName=<NLDAS NetCDF File>\n",
    "    dstGridName=<WRF-Hydro geo_em.d01.nc>\n",
    "    NLDAS2WRFHydro_generate_weights.ncl\n",
    "```\n",
    "\n",
    "This will create the following files:\n",
    "\n",
    "```\n",
    "DAS2WRFHydro_weight_bilinear.nc  \n",
    "PET0.RegridWeightGen.Log  \n",
    "SCRIP_NLDAS_bilinear.nc  \n",
    "SCRIP_WRFHydro_bilinear.nc  \n",
    "```\n",
    "\n",
    "First, make sure that the NCAR Command Language is installed. Detailed instructions can be found [here](https://www.ncl.ucar.edu/Download/conda.shtml). This following cell will install `ncl` into your conda environment if it doesn't already exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# install the ncl language in the conda environment, if it's not already installed.\n",
    "if  which ncl >/dev/null; then\n",
    "    echo NCL is already installed!\n",
    "else\n",
    "    conda install -y ncl\n",
    "fi\n",
    "\n",
    "#!conda install -y ncl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the regridding weight file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "FILE=`find input_files -name '*.grb' | head -1`\n",
    "echo $FILE\n",
    "\n",
    "ncl 'interp_opt=\"bilinear\"' \\\n",
    "'srcGridName=\"'$FILE'\"' \\\n",
    "'dstGridName=\"DOMAIN/geo_em.d01.nc\"' \\\n",
    "NLDAS2WRFHydro_generate_weights.ncl\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regrid all of the NLDAS files in the `input_files` directory using the NLDAS2WRFHydro_regrid.ncl script. This script takes NLDAS data and a weight file as inputs and outputs regridded data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "ncl 'srcFileName=\"NLDAS_FORA0125_H.*\"'\\\n",
    " 'dstGridName=\"DOMAIN/geo_em.d01.nc\"' \\\n",
    "NLDAS2WRFHydro_regrid.ncl\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean the our directory by (1) removing the raw NLDAS data that we downloaded from EarthData and (2) rename the default `output_files` directory to `FORCING`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf input_files\n",
    "!mv output_files FORCING\n",
    "!ls FORCING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next notebook demonstrates how these `FORCING` data can be used to run the WRF-Hydro model. However, execution of the model must be completed on your local machine, so first we'll save our data to HydroShare. Replace the `<abstract>`, `<title>`, and `<keyword>`, placeholders below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities import hydroshare\n",
    "hs = hydroshare.hydroshare()\n",
    "\n",
    "# compress the DOMAIN and FORCING directories\n",
    "!tar -czf wrfhydro-data.tar.gz DOMAIN FORCING\n",
    "\n",
    "# lets save this content as a new resource in HydroShare\n",
    "abstract = '<abstract>'\n",
    "title = '<title>'    \n",
    "keywords = ['<keyword>', '<keyword>2']         \n",
    "\n",
    "# create the new resource\n",
    "resource_id = hs.createHydroShareResource(abstract, \n",
    "                                          title, \n",
    "                                          keywords=keywords, \n",
    "                                          resource_type='compositeresource', \n",
    "                                          content_files=['wrfhydro-data.tar.gz',\n",
    "                                                         'WRFHydro-Domain.ipynb',\n",
    "                                                         'WRFHydro-Forcing.ipynb,\n",
    "                                                         'WRFHydro-Simulation.ipynb'], \n",
    "                                          public=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
